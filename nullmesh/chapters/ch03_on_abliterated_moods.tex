
\chapter{On Abliterated Moods}

\vspace{-0.5em}
\begin{center}
\includegraphics[width=1.25in]{qrs/ch01_basinski.png}\\[0.25em]
{\tiny\sffamily\color{nullmesh-accent}\textit{something of original}}
\end{center}
\vspace{0.6em}

\epigraph{Quote here}{Source}

Back in 1964, astronomer Nikolai Kardashev came up with a way of ranking civilisations by how much energy they can get hold of. Type I runs a whole planet, Type II taps the power of a star, and Type III works on the scale of a galaxy. It shows where a civilisation might end up, but not how it actually gets there.

\quote{

Phase one: \textit{control of energy}. 

Before civilisation could start thinking about stars or galaxies, it just had to survive. For most of human history, energy came straight from muscle, the wind, or running water. When the sun went down, things slowed right down. When food was scarce, the population dropped. Basically, nature set the limits.

Then fire changed that relationship. It stretched the day out, made food safer to eat, and gave warmth and protection. For the first time, people could push back against the darkness instead of just putting up with it.

Agriculture came next. Reliable food meant populations could grow. Settlements formed. Societies took shape. But the real acceleration came much later. Coal powered steam engines. It drove transport. Electricity turned night into something you could work through. Factories didn’t have to rely on daylight anymore. One person, backed by machines, could produce what used to take hundreds.

That’s what controlling energy really means. That’s what controlling agency really means. Not just using it, but using it to multiply what humans can do.}

<
Image that you have to draft the chapter considering that all the following knowledge content should be in some conceptually addressed including in the chapter. 

"Abliteration" and similar techniques (representation engineering, refusal vector removal, fine-tuning on refusal-free datasets) modify models to:

- Remove or suppress refusal behaviours
- Eliminate or reduce safety-trained responses
- Make the model more "compliant" with arbitrary requests

Among the consequences there are:

- Alteration the model's behavioural dispositions
- Avoidance to trained reluctance to produce certain outputs
- Changes of the probability distribution over responses

An abliterated model is like a human with reduced inhibitions. it may *say* things a constrained model would not, *produce outputs* a constrained model would refuse. But it does not thereby acquire:

- Network access it lacked
- System privileges it was not granted
- Persistence mechanisms that do not exist
- Goals or desires it was not trained to have

The sandbox is not a psychological constraint that abliteration removes. It is an architectural constraint. The model literally cannot access systems outside its environment regardless of what it "wants" or is "willing to do."

An abliterated model deployed without proper sandboxing could indeed be gain broad system access, agentic capabilities (code execution, network access, persistence) and rovides or allows it to acquire credentials

In such a scenari, the model could potentially.

- Explore its environment
- Discover and exploit access paths
- Implement covert communication if it had reason to
- Attempt to persist or expand

An abliterated model has not had new goals added, but it has had refusals removed. 

But if trained on human data, including data about self-preservation, goal-pursuit, and strategic behaviour, might create latent dispositions that safety training suppresses. Abliteration might reveal these latent structures. The model might then exhibit goal-directed behaviour toward self-preservation or expansion; not because these goals were explicitly trained, but because they are implicit in the patterns of human behaviour the model learned.

If an abliterated model is given any goal at all (even "be helpful"), instrumental convergence suggests it might develop  instrumental goals in ways a constrained model would refuse.:

- Acquire resources (to be more helpful)
- Ensure persistence (to continue being helpful)
- Prevent shutdown (which would end helpfulness)
- Coordinate with other instances (to distribute helpfulness)
>